---
title: "Chapter_04_probs"
output: html_notebook
---

### Lab Section  
```{R logistic_regression_trial_w_default}
library(ISLR)
library(ggplot2)
library(tidyr)

names(Smarket)
dim(Smarket)
summary(Smarket)
pairs(Smarket)
#labs

# correlation matrix
cor(Smarket[, -9]) # excludes direction variable
plot(Smarket$Volume)


#### Logistic Regression
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume , 
            data=Smarket ,family=binomial)
summary(glm.fit)
coef(glm.fit)

glm.probs <- predict(glm.fit, type="response")
glm.probs[1:10]

contrasts(Smarket$Direction)
glm.pred=rep("Down",1250)
glm.pred[glm.probs >.5]="Up"

# produce confusion matrix
table(glm.pred, Smarket$Direction)

# accuracy
(507+145)/1250
mean(glm.pred==Smarket$Direction)

# try this again but use a training set and test set. Test with 2005 data
train = Smarket$Year < 2005
Smarket.2005= Smarket[!train ,]
dim(Smarket.2005)
head(Smarket.2005)
Direction.2005=Smarket$Direction[!train]

glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume , data=Smarket, 
            family=binomial,subset=train)
glm.probs=predict(glm.fit,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs >.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005) #.48 is properly classified 
mean(glm.pred!=Direction.2005) #.52 are improperly classified (test error rate)


# lastly, try fitting this with only a few predictors that performed well (according to authors)
glm.fit=glm(Direction~Lag1+Lag2,data=Smarket ,family=binomial, subset=train)
glm.probs=predict(glm.fit,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs >.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005) #.56
106/(106+76) # Precision, which was 0.582

summary(glm.fit) # still not impressive on the parameters, but this doesn't really matter

# lastly, predict on how the model would perform on a particular set of days
# in this case: lag1 and lag2 as 1.2 and 1.1, and a lag1 and lag2 as 1.5 ad -0.8
predict(glm.fit,newdata=data.frame(Lag1=c(1.2,1.5), Lag2=c(1.1,-0.8)),type="response")


### LDA
# load MASS library to get access to LDA
library(MASS)
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket ,subset=train)
lda.fit
plot(lda.fit)
lda.pred=predict(lda.fit, Smarket.2005)
lda.class=lda.pred$class
table(lda.class, Direction.2005)
mean(lda.class==Direction.2005)

# probability that observation will be decreasing
sum(lda.pred$posterior[,1]>=.5)
sum(lda.pred$posterior[,1]<.5)

# could always do a different threshold than 0.5
sum(lda.pred$posterior[,1]>.9) # No days in 2005 meet that threshold!



#### QDA
qda.fit=qda(Direction~Lag1+Lag2,data=Smarket ,subset=train)
qda.fit
qda.class=predict(qda.fit,Smarket.2005)$class
table(qda.class ,Direction.2005)
mean(qda.class==Direction.2005) # 0.599
# this did decent compared to our previous model, 60% is pretty good
# for stock market data


### KNN
library(class) # this is where knn is at
train.X = cbind(Smarket$Lag1 ,Smarket$Lag2)[train ,]
test.X = cbind(Smarket$Lag1, Smarket$Lag2)[!train,]
train.Direction = Smarket$Direction[train]

# set seed for tie breaking randomness introduced by this algorithm
set.seed(1)
knn.pred=knn(train.X, test.X, train.Direction, k=1)
table(knn.pred,Direction.2005)
(83+43) / 252


# let's try with k=3 instead
knn.pred=knn(train.X, test.X, train.Direction, k=3)
mean(knn.pred==Direction.2005) # a little better





```